{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.feature_engineering_catboost import X_Transformer_scaled\n",
    "from ipynb.fs.full.feature_engineering_catboost import X_Transformer\n",
    "from ipynb.fs.full.feature_engineering_catboost import DataLoader\n",
    "from ipynb.fs.full.feature_engineering_catboost import TargetNormalizedRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from ipynb.fs.full.feature_engineering_final import BlendingRegressor\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import plot_tree\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from xgboost import plot_tree\n",
    "from matplotlib.pylab import rcParams\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/victor/anaconda3/lib/python3.6/site-packages/scipy/stats/stats.py:3399: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "/home/victor/anaconda3/lib/python3.6/site-packages/scipy/stats/stats.py:3429: PearsonRNearConstantInputWarning: An input array is nearly constant; the computed correlation coefficent may be inaccurate.\n",
      "  warnings.warn(PearsonRNearConstantInputWarning())\n"
     ]
    }
   ],
   "source": [
    "data_loader = DataLoader(\"train.csv\",\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_loader.getX_train()\n",
    "Y_train = data_loader.getY_train()\n",
    "X_test = data_loader.getX_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_transformer = X_Transformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10,shuffle = True,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm = LGBMRegressor(objective='regression', \n",
    "                                       num_leaves=4,\n",
    "                                       learning_rate=0.01, \n",
    "                                       n_estimators=4700,\n",
    "                                       max_bin=200, \n",
    "                                       bagging_fraction=0.85,\n",
    "                                       bagging_freq=5, \n",
    "                                       bagging_seed=7,\n",
    "                                       feature_fraction=0.3,\n",
    "                                       feature_fraction_seed=7,\n",
    "                                       verbose=-1,\n",
    "                                       categorical_feature = \"auto\",\n",
    "                                       max_cat_to_onehot = 4,\n",
    "                                       min_data_per_group = 24,  \n",
    "                                       cat_l2 = 0                               \n",
    "                                       )\n",
    "\n",
    "lgbm_t = TargetNormalizedRegressor(lgbm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/victor/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:741: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "/home/victor/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:762: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('preprocess',\n",
       "                 Pipeline(memory=None,\n",
       "                          steps=[('col_drop',\n",
       "                                  ColumnDrop(columns=['Utilities', 'Street',\n",
       "                                                      'PoolQC'])),\n",
       "                                 ('col_transformer',\n",
       "                                  ColumnTransformer(n_jobs=None,\n",
       "                                                    remainder='passthrough',\n",
       "                                                    sparse_threshold=0.3,\n",
       "                                                    transformer_weights=None,\n",
       "                                                    transformers=[('categorical_with_missing_values_const',\n",
       "                                                                   PipelineWithFeatureNames(feature_names=['...\n",
       "                                                                   learning_rate=0.01,\n",
       "                                                                   max_bin=200,\n",
       "                                                                   max_cat_to_onehot=4,\n",
       "                                                                   max_depth=-1,\n",
       "                                                                   min_child_samples=20,\n",
       "                                                                   min_child_weight=0.001,\n",
       "                                                                   min_data_per_group=24,\n",
       "                                                                   min_split_gain=0.0,\n",
       "                                                                   n_estimators=4700,\n",
       "                                                                   n_jobs=-1,\n",
       "                                                                   num_leaves=5,\n",
       "                                                                   objective='regression',\n",
       "                                                                   random_state=None,\n",
       "                                                                   reg_alpha=0.0,\n",
       "                                                                   reg_lambda=0.0,\n",
       "                                                                   silent=True,\n",
       "                                                                   subsample=1.0,\n",
       "                                                                   subsample_for_bin=200000,\n",
       "                                                                   subsample_freq=0, ...)))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_pipeline = Pipeline(steps=[('preprocess', x_transformer),('learn',lgbm_t)])\n",
    "learning_pipeline.fit(X_train,y=Y_train)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up the parameters\n",
    "#rcParams['figure.figsize'] = 100,90\n",
    "#plot_tree(learning_pipeline.named_steps['learn'],num_trees=2799, rankdir='LR')#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ypredicted = learning_pipeline.predict(X_test)\n",
    "#Ypredicted =   #pd.read_csv('submission_stack_elasticnet.csv').iloc[:,1]\n",
    "#Ypredicted = pd.read_csv('submission_stack_ridge.csv').iloc[:,1]*0.5 + pd.read_csv('submission_stack_elasticnet.csv').iloc[:,1]*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultDf = pd.DataFrame()\n",
    "resultDf['Id'] = data_loader.get_Test_id()\n",
    "resultDf['SalePrice'] = Ypredicted\n",
    "\n",
    "#q1 = resultDf['SalePrice'].quantile(0.0045)\n",
    "#q2 = resultDf['SalePrice'].quantile(0.99)\n",
    "#resultDf[resultDf['SalePrice'] <= q1]\n",
    "#resultDf[resultDf['SalePrice'] <= q1]\n",
    "\n",
    "#resultDf['SalePrice'] = resultDf['SalePrice'].apply(lambda x: x if x > q1 else x*0.9)\n",
    "#resultDf['SalePrice'] = resultDf['SalePrice'].apply(lambda x: x if x < q2 else x*1.081)\n",
    "\n",
    "#resultDf\n",
    "resultDf.to_csv('submission.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

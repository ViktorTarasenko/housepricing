{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.feature_engineering_final import X_Transformer_scaled\n",
    "from ipynb.fs.full.feature_engineering_final import X_Transformer\n",
    "from ipynb.fs.full.feature_engineering_final import DataLoader\n",
    "from ipynb.fs.full.feature_engineering_final import TargetNormalizedRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from ipynb.fs.full.feature_engineering_final import BlendingRegressor\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import plot_tree\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from xgboost import plot_tree\n",
    "from matplotlib.pylab import rcParams\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/victor/anaconda3/lib/python3.6/site-packages/scipy/stats/stats.py:3399: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "/home/victor/anaconda3/lib/python3.6/site-packages/scipy/stats/stats.py:3429: PearsonRNearConstantInputWarning: An input array is nearly constant; the computed correlation coefficent may be inaccurate.\n",
      "  warnings.warn(PearsonRNearConstantInputWarning())\n"
     ]
    }
   ],
   "source": [
    "data_loader = DataLoader(\"train.csv\",\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_loader.getX_train()\n",
    "Y_train = data_loader.getY_train()\n",
    "X_test = data_loader.getX_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_transformer = X_Transformer_scaled()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10,shuffle = True,random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBRegressor(objective='reg:squarederror',eval_metric = 'rmse',learning_rate=0.01,n_estimators=4900,\n",
    "                                     max_depth=3, min_child_weight=0,\n",
    "                                     gamma=0, subsample=0.7,\n",
    "                                     colsample_bytree=0.7,\n",
    "                                     nthread=-1,\n",
    "                                     scale_pos_weight=1, seed=27,\n",
    "                                     reg_alpha=0.00006)\n",
    "xgb_t = TargetNormalizedRegressor(xgb)\n",
    "\n",
    "svr = SVR(kernel=\"rbf\",gamma=0.0003,C = 14,epsilon = 0.00008)\n",
    "\n",
    "svr_t = TargetNormalizedRegressor(svr)\n",
    "\n",
    "ridge = RidgeCV(cv=10)\n",
    "\n",
    "ridge_t = TargetNormalizedRegressor(ridge)\n",
    "\n",
    "lasso = LassoCV(cv=10)\n",
    "lasso_t = TargetNormalizedRegressor(lasso)\n",
    "\n",
    "elastic_net = ElasticNetCV(max_iter=1e7, alphas=[0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007],\n",
    "                                        cv=kf, l1_ratio=[0.8, 0.85, 0.9, 0.95, 0.99, 1])\n",
    "elastic_net_t = TargetNormalizedRegressor(elastic_net)\n",
    "\n",
    "gbr = GradientBoostingRegressor(n_estimators=5950, learning_rate=0.01,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   loss='huber', random_state =42,subsample = 0.7)\n",
    "\n",
    "gbr_t = TargetNormalizedRegressor(gbr)\n",
    "\n",
    "\n",
    "scvr = StackingCVRegressor(regressors=(xgb,svr,ridge,lasso,elastic_net,gbr),\n",
    "                                meta_regressor=ridge,cv=15,\n",
    "                                use_features_in_secondary=True,\n",
    "                                  n_jobs = -1)\n",
    "scvr_t = TargetNormalizedRegressor(scvr)\n",
    "\n",
    "lightgbm = LGBMRegressor(objective='regression',num_leaves=4, learning_rate=0.01, \n",
    "              n_estimators=5000, max_bin=200, \n",
    "              bagging_fraction=0.75, bagging_freq=1, \n",
    "              bagging_seed=7, feature_fraction=0.2,feature_fraction_seed=7,\n",
    "                                       verbose=-1)\n",
    "\n",
    "#blrgr = TargetNormalizedRegressor(BlendingRegressor(regressors_and_weights = [(xgb,0.139342855),(svr,0.140628783),(ridge,0.143950385),(lasso,0.1430492),(elastic_net,0.144500587),(gbr,0.141916906)]))\n",
    "#blrgr = BlendingRegressor(regressors_and_weights = [(svr_t,0.5)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('preprocess',\n",
       "                 Pipeline(memory=None,\n",
       "                          steps=[('col_drop',\n",
       "                                  ColumnDrop(columns=['Utilities', 'Street',\n",
       "                                                      'PoolQC'])),\n",
       "                                 ('col_transformer',\n",
       "                                  ColumnTransformer(n_jobs=None,\n",
       "                                                    remainder='passthrough',\n",
       "                                                    sparse_threshold=0.3,\n",
       "                                                    transformer_weights=None,\n",
       "                                                    transformers=[('categorical_with_missing_values_const',\n",
       "                                                                   PipelineWithFeatureNames(feature_names=['...\n",
       "                                                                               learning_rate=0.01,\n",
       "                                                                               loss='huber',\n",
       "                                                                               max_depth=4,\n",
       "                                                                               max_features='sqrt',\n",
       "                                                                               max_leaf_nodes=None,\n",
       "                                                                               min_impurity_decrease=0.0,\n",
       "                                                                               min_impurity_split=None,\n",
       "                                                                               min_samples_leaf=1,\n",
       "                                                                               min_samples_split=2,\n",
       "                                                                               min_weight_fraction_leaf=0.0,\n",
       "                                                                               n_estimators=5950,\n",
       "                                                                               n_iter_no_change=None,\n",
       "                                                                               presort='auto',\n",
       "                                                                               random_state=42,\n",
       "                                                                               subsample=0.7,\n",
       "                                                                               tol=0.0001,\n",
       "                                                                               validation_fraction=0.1,\n",
       "                                                                               verbose=0,\n",
       "                                                                               warm_start=False)))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_pipeline = Pipeline(steps=[('preprocess', x_transformer),('learn',gbr_t)])\n",
    "learning_pipeline.fit(X_train,y=Y_train)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up the parameters\n",
    "#rcParams['figure.figsize'] = 100,90\n",
    "#plot_tree(learning_pipeline.named_steps['learn'],num_trees=2799, rankdir='LR')#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ypredicted = learning_pipeline.predict(X_test)\n",
    "#Ypredicted =   #pd.read_csv('submission_stack_elasticnet.csv').iloc[:,1]\n",
    "#Ypredicted = pd.read_csv('submission_stack_ridge.csv').iloc[:,1]*0.5 + pd.read_csv('submission_stack_elasticnet.csv').iloc[:,1]*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultDf = pd.DataFrame()\n",
    "resultDf['Id'] = data_loader.get_Test_id()\n",
    "resultDf['SalePrice'] = Ypredicted\n",
    "\n",
    "#q1 = resultDf['SalePrice'].quantile(0.0045)\n",
    "#q2 = resultDf['SalePrice'].quantile(0.99)\n",
    "#resultDf[resultDf['SalePrice'] <= q1]\n",
    "#resultDf[resultDf['SalePrice'] <= q1]\n",
    "\n",
    "#resultDf['SalePrice'] = resultDf['SalePrice'].apply(lambda x: x if x > q1 else x*0.9)\n",
    "#resultDf['SalePrice'] = resultDf['SalePrice'].apply(lambda x: x if x < q2 else x*1.081)\n",
    "\n",
    "#resultDf\n",
    "resultDf.to_csv('submission_gbr.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

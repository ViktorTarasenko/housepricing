{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.feature_engineering_final import X_Transformer_scaled\n",
    "from ipynb.fs.full.feature_engineering_final import X_Transformer\n",
    "from ipynb.fs.full.feature_engineering_final import DataLoader\n",
    "from ipynb.fs.full.feature_engineering_final import TargetNormalizedRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from ipynb.fs.full.feature_engineering_final import BlendingRegressor\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import plot_tree\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from xgboost import plot_tree\n",
    "from matplotlib.pylab import rcParams\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/victor/anaconda3/lib/python3.6/site-packages/scipy/stats/stats.py:3399: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "/home/victor/anaconda3/lib/python3.6/site-packages/scipy/stats/stats.py:3429: PearsonRNearConstantInputWarning: An input array is nearly constant; the computed correlation coefficent may be inaccurate.\n",
      "  warnings.warn(PearsonRNearConstantInputWarning())\n"
     ]
    }
   ],
   "source": [
    "data_loader = DataLoader(\"train.csv\",\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_loader.getX_train()\n",
    "Y_train = data_loader.getY_train()\n",
    "X_test = data_loader.getX_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_transformer = X_Transformer_scaled()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10,shuffle = True,random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBRegressor(objective='reg:squarederror',eval_metric = 'rmse',learning_rate=0.01,n_estimators=3460,\n",
    "                                     max_depth=3, min_child_weight=0,\n",
    "                                     gamma=0, subsample=0.7,\n",
    "                                     colsample_bytree=0.7,\n",
    "                                     nthread=-1,\n",
    "                                     scale_pos_weight=1, seed=27,\n",
    "                                     reg_alpha=0.00006)\n",
    "\n",
    "svr = SVR(kernel=\"rbf\",gamma=0.0003,C = 30,epsilon = 0.00008)\n",
    "\n",
    "ridge = RidgeCV(alphas=[14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5])\n",
    "\n",
    "lasso = LassoCV(cv=10)\n",
    "\n",
    "elastic_net = ElasticNetCV(max_iter=1e7, alphas=[0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007],\n",
    "                                        cv=kf, l1_ratio=[0.8, 0.85, 0.9, 0.95, 0.99, 1])\n",
    "\n",
    "gbr = GradientBoostingRegressor(n_estimators=3700, learning_rate=0.01,\n",
    "                                   max_depth=3, max_features='sqrt',\n",
    "                                   loss='huber', random_state =42,subsample = 0.7)\n",
    "\n",
    "\n",
    "scvr = StackingCVRegressor(regressors=(xgb,svr,ridge,lasso,elastic_net,gbr),\n",
    "                                meta_regressor=elastic_net,cv=10,\n",
    "                                use_features_in_secondary=True,\n",
    "                                  n_jobs = -1)\n",
    "lightgbm = LGBMRegressor(objective='regression',num_leaves=4, learning_rate=0.01, \n",
    "              n_estimators=5000, max_bin=200, \n",
    "              bagging_fraction=0.75, bagging_freq=5, \n",
    "              bagging_seed=7, feature_fraction=0.2,feature_fraction_seed=7,\n",
    "                                       verbose=-1)\n",
    "\n",
    "blrgr = TargetNormalizedRegressor(BlendingRegressor(regressors_and_weights = [(scvr,0.3),(xgb,0.05),(svr,0.1),(ridge,0.15),(lasso,0.15),(elastic_net,0.15),(gbr,0.05),(lightgbm,0.05)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/victor/anaconda3/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('preprocess',\n",
       "                 Pipeline(memory=None,\n",
       "                          steps=[('col_drop',\n",
       "                                  ColumnDrop(columns=['Utilities', 'Street',\n",
       "                                                      'PoolQC'])),\n",
       "                                 ('col_transformer',\n",
       "                                  ColumnTransformer(n_jobs=None,\n",
       "                                                    remainder='passthrough',\n",
       "                                                    sparse_threshold=0.3,\n",
       "                                                    transformer_weights=None,\n",
       "                                                    transformers=[('categorical_with_missing_values_const',\n",
       "                                                                   PipelineWithFeatureNames(feature_names=['...\n",
       "                                                                                                              feature_fraction_seed=7,\n",
       "                                                                                                              importance_type='split',\n",
       "                                                                                                              learning_rate=0.01,\n",
       "                                                                                                              max_bin=200,\n",
       "                                                                                                              max_depth=-1,\n",
       "                                                                                                              min_child_samples=20,\n",
       "                                                                                                              min_child_weight=0.001,\n",
       "                                                                                                              min_split_gain=0.0,\n",
       "                                                                                                              n_estimators=5000,\n",
       "                                                                                                              n_jobs=-1,\n",
       "                                                                                                              num_leaves=4,\n",
       "                                                                                                              objective='regression',\n",
       "                                                                                                              random_state=None,\n",
       "                                                                                                              reg_alpha=0.0,\n",
       "                                                                                                              reg_lambda=0.0,\n",
       "                                                                                                              silent=True,\n",
       "                                                                                                              subsample=1.0,\n",
       "                                                                                                              subsample_for_bin=200000,\n",
       "                                                                                                              subsample_freq=0,\n",
       "                                                                                                              verbose=-1),\n",
       "                                                                                                0.05)])))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_pipeline = Pipeline(steps=[('preprocess', x_transformer),('learn',blrgr)])\n",
    "learning_pipeline.fit(X_train,y=Y_train)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up the parameters\n",
    "#rcParams['figure.figsize'] = 100,90\n",
    "#plot_tree(learning_pipeline.named_steps['learn'],num_trees=2799, rankdir='LR')#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ypredicted = learning_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultDf = pd.DataFrame()\n",
    "resultDf['Id'] = data_loader.get_Test_id()\n",
    "resultDf['SalePrice'] = Ypredicted\n",
    "\n",
    "#q1 = resultDf['SalePrice'].quantile(0.0045)\n",
    "#q2 = resultDf['SalePrice'].quantile(0.99)\n",
    "\n",
    "#resultDf['SalePrice'] = resultDf['SalePrice'].apply(lambda x: x if x > q1 else x*0.77)\n",
    "#resultDf['SalePrice'] = resultDf['SalePrice'].apply(lambda x: x if x < q2 else x*1.1)\n",
    "\n",
    "resultDf\n",
    "resultDf.to_csv('submission.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

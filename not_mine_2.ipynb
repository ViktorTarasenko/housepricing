{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet \n",
    "\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "# ------------ Reading and cleaning data ------------ \n",
    "mydata = pd.read_csv('train.csv')\n",
    "\n",
    "# As suggested by many participants, we remove several outliers\n",
    "mydata.drop(mydata[(mydata['OverallQual']<5) & (mydata['SalePrice']>200000)].index, inplace=True)\n",
    "mydata.drop(mydata[(mydata['GrLivArea']>4000) & (mydata['SalePrice']<300000)].index, inplace=True)\n",
    "mydata.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Some of the non-numeric predictors are stored as numbers; we convert them into strings \n",
    "mydata['MSSubClass'] = mydata['MSSubClass'].apply(str)\n",
    "mydata['YrSold'] = mydata['YrSold'].astype(str)\n",
    "mydata['MoSold'] = mydata['MoSold'].astype(str)\n",
    "# ------------ Function to fill in missings ------------ \n",
    "# Here we create funtion which fills all the missing values\n",
    "# Pay attention that some of the missing values of numeric predictors first are filled in with zeros and then \n",
    "# small values are filled in with median/average (and indicator variables are created to account for such change: \n",
    "# for each variable we create  which are equal to one);\n",
    "\n",
    "def fill_missings(res):\n",
    "\n",
    "    res['Alley'] = res['Alley'].fillna('missing')\n",
    "    res['PoolQC'] = res['PoolQC'].fillna(res['PoolQC'].mode()[0])\n",
    "    res['MasVnrType'] = res['MasVnrType'].fillna('None')\n",
    "    res['BsmtQual'] = res['BsmtQual'].fillna(res['BsmtQual'].mode()[0])\n",
    "    res['BsmtCond'] = res['BsmtCond'].fillna(res['BsmtCond'].mode()[0])\n",
    "    res['FireplaceQu'] = res['FireplaceQu'].fillna(res['FireplaceQu'].mode()[0])\n",
    "    res['GarageType'] = res['GarageType'].fillna('missing')\n",
    "    res['GarageFinish'] = res['GarageFinish'].fillna(res['GarageFinish'].mode()[0])\n",
    "    res['GarageQual'] = res['GarageQual'].fillna(res['GarageQual'].mode()[0])\n",
    "    res['GarageCond'] = res['GarageCond'].fillna('missing')\n",
    "    res['Fence'] = res['Fence'].fillna('missing')\n",
    "    res['Street'] = res['Street'].fillna('missing')\n",
    "    res['LotShape'] = res['LotShape'].fillna('missing')\n",
    "    res['LandContour'] = res['LandContour'].fillna('missing')\n",
    "    res['BsmtExposure'] = res['BsmtExposure'].fillna(res['BsmtExposure'].mode()[0])\n",
    "    res['BsmtFinType1'] = res['BsmtFinType1'].fillna('missing')\n",
    "    res['BsmtFinType2'] = res['BsmtFinType2'].fillna('missing')\n",
    "    res['CentralAir'] = res['CentralAir'].fillna('missing')\n",
    "    res['Electrical'] = res['Electrical'].fillna(res['Electrical'].mode()[0])\n",
    "    res['MiscFeature'] = res['MiscFeature'].fillna('missing')\n",
    "    res['MSZoning'] = res['MSZoning'].fillna(res['MSZoning'].mode()[0])    \n",
    "    res['Utilities'] = res['Utilities'].fillna('missing')\n",
    "    res['Exterior1st'] = res['Exterior1st'].fillna(res['Exterior1st'].mode()[0])\n",
    "    res['Exterior2nd'] = res['Exterior2nd'].fillna(res['Exterior2nd'].mode()[0])    \n",
    "    res['KitchenQual'] = res['KitchenQual'].fillna(res['KitchenQual'].mode()[0])\n",
    "    res[\"Functional\"] = res[\"Functional\"].fillna(\"Typ\")\n",
    "    res['SaleType'] = res['SaleType'].fillna(res['SaleType'].mode()[0])\n",
    "    res['SaleCondition'] = res['SaleCondition'].fillna('missing')\n",
    "    \n",
    "    flist = ['LotFrontage','LotArea','MasVnrArea','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF',\n",
    "                     'TotalBsmtSF','1stFlrSF','2ndFlrSF','LowQualFinSF','GrLivArea',\n",
    "                     'BsmtFullBath','BsmtHalfBath','FullBath','HalfBath','BedroomAbvGr','KitchenAbvGr',\n",
    "                     'TotRmsAbvGrd','Fireplaces','GarageCars','GarageArea','WoodDeckSF','OpenPorchSF',\n",
    "                     'EnclosedPorch','3SsnPorch','ScreenPorch','PoolArea','MiscVal']\n",
    "    for fl in flist:\n",
    "        res[fl] = res[fl].fillna(0)\n",
    "        \n",
    "    res['TotalBsmtSF'] = res['TotalBsmtSF'].apply(lambda x: np.exp(6) if x <= 0.0 else x)\n",
    "    res['2ndFlrSF'] = res['2ndFlrSF'].apply(lambda x: np.exp(6.5) if x <= 0.0 else x)\n",
    "    res['GarageArea'] = res['GarageArea'].apply(lambda x: np.exp(6) if x <= 0.0 else x)\n",
    "    res['GarageCars'] = res['GarageCars'].apply(lambda x: 0 if x <= 0.0 else x)\n",
    "    res['LotFrontage'] = res['LotFrontage'].apply(lambda x: np.exp(4.2) if x <= 0.0 else x)\n",
    "    res['MasVnrArea'] = res['MasVnrArea'].apply(lambda x: np.exp(4) if x <= 0.0 else x)\n",
    "    res['BsmtFinSF1'] = res['BsmtFinSF1'].apply(lambda x: np.exp(6.5) if x <= 0.0 else x)\n",
    "    \n",
    "      \n",
    "    return res\n",
    "# ------------- Filling in missing values, re-coding ordinal variables -------------\n",
    "# Running function to fill in missings\n",
    "mydata = fill_missings(mydata)\n",
    "mydata['TotalSF'] = mydata['TotalBsmtSF'] + mydata['1stFlrSF'] + mydata['2ndFlrSF']\n",
    "\n",
    "# Working with ordinal predictors\n",
    "def QualToInt(x):\n",
    "    if(x=='Ex'):\n",
    "        r = 0\n",
    "    elif(x=='Gd'):\n",
    "        r = 1\n",
    "    elif(x=='TA'):\n",
    "        r = 2\n",
    "    elif(x=='Fa'):\n",
    "        r = 3\n",
    "    elif(x=='missing'):\n",
    "        r = 4\n",
    "    else:\n",
    "        r = 5\n",
    "    return r\n",
    "\n",
    "mydata['ExterQual'] = mydata['ExterQual'].apply(QualToInt)\n",
    "mydata['ExterCond'] = mydata['ExterCond'].apply(QualToInt)\n",
    "mydata['KitchenQual'] = mydata['KitchenQual'].apply(QualToInt)\n",
    "mydata['HeatingQC'] = mydata['HeatingQC'].apply(QualToInt)\n",
    "mydata['BsmtQual'] = mydata['BsmtQual'].apply(QualToInt)\n",
    "mydata['BsmtCond'] = mydata['BsmtCond'].apply(QualToInt)\n",
    "mydata['FireplaceQu'] = mydata['FireplaceQu'].apply(QualToInt)\n",
    "mydata['GarageQual'] = mydata['GarageQual'].apply(QualToInt)\n",
    "mydata['PoolQC'] = mydata['PoolQC'].apply(QualToInt)\n",
    "\n",
    "def SlopeToInt(x):\n",
    "    if(x=='Gtl'):\n",
    "        r = 0\n",
    "    elif(x=='Mod'):\n",
    "        r = 1\n",
    "    elif(x=='Sev'):\n",
    "        r = 2\n",
    "    else:\n",
    "        r = 3\n",
    "    return r\n",
    "\n",
    "mydata['LandSlope'] = mydata['LandSlope'].apply(SlopeToInt)\n",
    "mydata['CentralAir'] = mydata['CentralAir'].apply( lambda x: 0 if x == 'N' else 1) \n",
    "mydata['Street'] = mydata['Street'].apply( lambda x: 0 if x == 'Pave' else 1) \n",
    "mydata['PavedDrive'] = mydata['PavedDrive'].apply( lambda x: 0 if x == 'Y' else 1)\n",
    "\n",
    "def GFinishToInt(x):\n",
    "    if(x=='Fin'):\n",
    "        r = 0\n",
    "    elif(x=='RFn'):\n",
    "        r = 1\n",
    "    elif(x=='Unf'):\n",
    "        r = 2\n",
    "    else:\n",
    "        r = 3\n",
    "    return r\n",
    "\n",
    "mydata['GarageFinish'] = mydata['GarageFinish'].apply(GFinishToInt)\n",
    "\n",
    "def BsmtExposureToInt(x):\n",
    "    if(x=='Gd'):\n",
    "        r = 0\n",
    "    elif(x=='Av'):\n",
    "        r = 1\n",
    "    elif(x=='Mn'):\n",
    "        r = 2\n",
    "    elif(x=='No'):\n",
    "        r = 3\n",
    "    else:\n",
    "        r = 4\n",
    "    return r\n",
    "mydata['BsmtExposure'] = mydata['BsmtExposure'].apply(BsmtExposureToInt)\n",
    "\n",
    "def FunctionalToInt(x):\n",
    "    if(x=='Typ'):\n",
    "        r = 0\n",
    "    elif(x=='Min1'):\n",
    "        r = 1\n",
    "    elif(x=='Min2'):\n",
    "        r = 1\n",
    "    else:\n",
    "        r = 2\n",
    "    return r\n",
    "\n",
    "mydata['Functional_int'] = mydata['Functional'].apply(FunctionalToInt)\n",
    "\n",
    "\n",
    "def HouseStyleToInt(x):\n",
    "    if(x=='1.5Unf'):\n",
    "        r = 0\n",
    "    elif(x=='SFoyer'):\n",
    "        r = 1\n",
    "    elif(x=='1.5Fin'):\n",
    "        r = 2\n",
    "    elif(x=='2.5Unf'):\n",
    "        r = 3\n",
    "    elif(x=='SLvl'):\n",
    "        r = 4\n",
    "    elif(x=='1Story'):\n",
    "        r = 5\n",
    "    elif(x=='2Story'):\n",
    "        r = 6  \n",
    "    elif(x==' 2.5Fin'):\n",
    "        r = 7          \n",
    "    else:\n",
    "        r = 8\n",
    "    return r\n",
    "\n",
    "mydata['HouseStyle_int'] = mydata['HouseStyle'].apply(HouseStyleToInt)\n",
    "mydata['HouseStyle_1st'] = 1*(mydata['HouseStyle'] == '1Story')\n",
    "mydata['HouseStyle_2st'] = 1*(mydata['HouseStyle'] == '2Story')\n",
    "mydata['HouseStyle_15st'] = 1*(mydata['HouseStyle'] == '1.5Fin')\n",
    "\n",
    "def FoundationToInt(x):\n",
    "    if(x=='PConc'):\n",
    "        r = 3\n",
    "    elif(x=='CBlock'):\n",
    "        r = 2\n",
    "    elif(x=='BrkTil'):\n",
    "        r = 1        \n",
    "    else:\n",
    "        r = 0\n",
    "    return r\n",
    "\n",
    "mydata['Foundation_int'] = mydata['Foundation'].apply(FoundationToInt)\n",
    "\n",
    "def MasVnrTypeToInt(x):\n",
    "    if(x=='Stone'):\n",
    "        r = 3\n",
    "    elif(x=='BrkFace'):\n",
    "        r = 2\n",
    "    elif(x=='BrkCmn'):\n",
    "        r = 1        \n",
    "    else:\n",
    "        r = 0\n",
    "    return r\n",
    "\n",
    "mydata['MasVnrType_int'] = mydata['MasVnrType'].apply(MasVnrTypeToInt)\n",
    "\n",
    "def BsmtFinType1ToInt(x):\n",
    "    if(x=='GLQ'):\n",
    "        r = 6\n",
    "    elif(x=='ALQ'):\n",
    "        r = 5\n",
    "    elif(x=='BLQ'):\n",
    "        r = 4\n",
    "    elif(x=='Rec'):\n",
    "        r = 3   \n",
    "    elif(x=='LwQ'):\n",
    "        r = 2\n",
    "    elif(x=='Unf'):\n",
    "        r = 1        \n",
    "    else:\n",
    "        r = 0\n",
    "    return r\n",
    "\n",
    "mydata['BsmtFinType1_int'] = mydata['BsmtFinType1'].apply(BsmtFinType1ToInt)\n",
    "mydata['BsmtFinType1_Unf'] = 1*(mydata['BsmtFinType1'] == 'Unf')\n",
    "mydata['HasWoodDeck'] = (mydata['WoodDeckSF'] == 0) * 1\n",
    "mydata['HasOpenPorch'] = (mydata['OpenPorchSF'] == 0) * 1\n",
    "mydata['HasEnclosedPorch'] = (mydata['EnclosedPorch'] == 0) * 1\n",
    "mydata['Has3SsnPorch'] = (mydata['3SsnPorch'] == 0) * 1\n",
    "mydata['HasScreenPorch'] = (mydata['ScreenPorch'] == 0) * 1\n",
    "mydata['YearsSinceRemodel'] = mydata['YrSold'].astype(int) - mydata['YearRemodAdd'].astype(int)\n",
    "mydata['Total_Home_Quality'] = mydata['OverallQual'] + mydata['OverallCond']\n",
    "# --------------- Adding log-transformed predictors to raw data --------------- \n",
    "def addlogs(res, ls):\n",
    "    m = res.shape[1]\n",
    "    for l in ls:\n",
    "        res = res.assign(newcol=pd.Series(np.log(1.01+res[l])).values)   \n",
    "        res.columns.values[m] = l + '_log'\n",
    "        m += 1\n",
    "    return res\n",
    "\n",
    "loglist = ['LotFrontage','LotArea','MasVnrArea','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF',\n",
    "                 'TotalBsmtSF','1stFlrSF','2ndFlrSF','LowQualFinSF','GrLivArea',\n",
    "                 'BsmtFullBath','BsmtHalfBath','FullBath','HalfBath','BedroomAbvGr','KitchenAbvGr',\n",
    "                 'TotRmsAbvGrd','Fireplaces','GarageCars','GarageArea','WoodDeckSF','OpenPorchSF',\n",
    "                 'EnclosedPorch','3SsnPorch','ScreenPorch','PoolArea','MiscVal','YearRemodAdd','TotalSF']\n",
    "\n",
    "mydata = addlogs(mydata, loglist)\n",
    "# ----------------- Creating dataset for training: adding dummies, adding numeric predictors -----------------\n",
    "def getdummies(res, ls):\n",
    "    def encode(encode_df):\n",
    "        encode_df = np.array(encode_df)\n",
    "        enc = OneHotEncoder()\n",
    "        le = LabelEncoder()\n",
    "        le.fit(encode_df)\n",
    "        res1 = le.transform(encode_df).reshape(-1, 1)\n",
    "        enc.fit(res1)\n",
    "        return pd.DataFrame(enc.transform(res1).toarray()), le, enc\n",
    "\n",
    "    decoder = []\n",
    "    outres = pd.DataFrame({'A' : []})\n",
    "\n",
    "    for l in ls:\n",
    "        cat, le, enc = encode(res[l])\n",
    "        cat.columns = [l+str(x) for x in cat.columns]\n",
    "        outres.reset_index(drop=True, inplace=True)\n",
    "        outres = pd.concat([outres, cat], axis = 1)\n",
    "        decoder.append([le,enc])     \n",
    "    \n",
    "    return (outres, decoder)\n",
    "\n",
    "catpredlist = ['MSSubClass','MSZoning','LotShape','LandContour','LotConfig',\n",
    "               'Neighborhood','Condition1','Condition2','BldgType',\n",
    "               'RoofStyle','RoofMatl','Exterior1st','Exterior2nd',\n",
    "               'BsmtFinType2','Heating','HouseStyle','Foundation','MasVnrType','BsmtFinType1',\n",
    "               'Electrical','Functional','GarageType','Alley','Utilities',\n",
    "               'GarageCond','Fence','MiscFeature','SaleType','SaleCondition','LandSlope','CentralAir',\n",
    "               'GarageFinish','BsmtExposure','Street']\n",
    "\n",
    "# Applying function to get dummies\n",
    "# Saving decoder - function which can be used to transform new data  \n",
    "res = getdummies(mydata[catpredlist],catpredlist)\n",
    "df = res[0]\n",
    "decoder = res[1]\n",
    "\n",
    "# Adding real valued features\n",
    "floatpredlist = ['LotFrontage_log',\n",
    "                 'LotArea_log',\n",
    "                 'MasVnrArea_log','BsmtFinSF1_log','BsmtFinSF2_log','BsmtUnfSF_log',\n",
    "                 'TotalBsmtSF_log','1stFlrSF_log','2ndFlrSF_log','LowQualFinSF_log','GrLivArea_log',\n",
    "                 'BsmtFullBath_log','BsmtHalfBath_log','FullBath_log','HalfBath_log','BedroomAbvGr_log','KitchenAbvGr_log',\n",
    "                 'TotRmsAbvGrd_log','Fireplaces_log','GarageCars_log','GarageArea_log',\n",
    "                 'PoolArea_log','MiscVal_log',\n",
    "                 'YearRemodAdd','TotalSF_log','OverallQual','OverallCond','ExterQual','ExterCond','KitchenQual',\n",
    "                 'HeatingQC','BsmtQual','BsmtCond','FireplaceQu','GarageQual','PoolQC','PavedDrive',\n",
    "                 'HasWoodDeck', 'HasOpenPorch','HasEnclosedPorch', 'Has3SsnPorch', 'HasScreenPorch']\n",
    "df = pd.concat([df,mydata[floatpredlist]],axis=1)\n",
    "# ----------------- Creating dataset for training: using function which creates squared predictors and adding them to the dataset -----------------\n",
    "def addSquared(res, ls):\n",
    "    m = res.shape[1]\n",
    "    for l in ls:\n",
    "        res = res.assign(newcol=pd.Series(res[l]*res[l]).values)   \n",
    "        res.columns.values[m] = l + '_sq'\n",
    "        m += 1\n",
    "    return res \n",
    "\n",
    "sqpredlist = ['YearRemodAdd', 'LotFrontage_log', \n",
    "              'TotalBsmtSF_log', '1stFlrSF_log', '2ndFlrSF_log', 'GrLivArea_log',\n",
    "              'GarageCars_log', 'GarageArea_log',\n",
    "              'OverallQual','ExterQual','BsmtQual','GarageQual','FireplaceQu','KitchenQual']\n",
    "df = addSquared(df, sqpredlist)\n",
    "# ------------- Converting data to numpy array ------------- \n",
    "X = np.array(df)\n",
    "X = np.delete(X, 0, axis=1)\n",
    "y = np.log(1+np.array(mydata['SalePrice']))\n",
    "# ------------- Modelling -------------\n",
    "# 30-fold cross-validation\n",
    "# Stacking: on each run of cross-validation I fit 5 models (l2, l1, GBR, ENet and LGB)\n",
    "# Then we make 5 predictions using these models on left-out fold and add geometric mean of these predictions\n",
    "# Finally, use lasso on these six predictors to forecast values on the left-out fold\n",
    "# Save all the models (in total we have 30*6=180 models)\n",
    "nF = 20\n",
    "\n",
    "kf = KFold(n_splits=nF, random_state=241, shuffle=True)\n",
    "\n",
    "test_errors_l2 = []\n",
    "train_errors_l2 = []\n",
    "test_errors_l1 = []\n",
    "train_errors_l1 = []\n",
    "test_errors_GBR = []\n",
    "train_errors_GBR = []\n",
    "test_errors_ENet = []\n",
    "test_errors_LGB = []\n",
    "test_errors_stack = []\n",
    "test_errors_ens = []\n",
    "train_errors_ens = []\n",
    "\n",
    "models = []\n",
    "\n",
    "pred_all = []\n",
    "\n",
    "ifold = 1\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print('fold: ',ifold)\n",
    "    ifold = ifold + 1\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # ridge\n",
    "    l2Regr = Ridge(alpha=9.0, fit_intercept = True)\n",
    "    l2Regr.fit(X_train, y_train)\n",
    "    pred_train_l2 = l2Regr.predict(X_train)\n",
    "    pred_test_l2 = l2Regr.predict(X_test)\n",
    "    \n",
    "    # lasso\n",
    "    l1Regr = make_pipeline(RobustScaler(), Lasso(alpha = 0.0003, random_state=1, max_iter=50000))\n",
    "    l1Regr.fit(X_train, y_train)\n",
    "    pred_train_l1 = l1Regr.predict(X_train)\n",
    "    pred_test_l1 = l1Regr.predict(X_test)\n",
    "    \n",
    "    # GBR      \n",
    "    myGBR = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.02,\n",
    "                                      max_depth=4, max_features='sqrt',\n",
    "                                      min_samples_leaf=15, min_samples_split=50,\n",
    "                                      loss='huber', random_state = 5) \n",
    "    \n",
    "    myGBR.fit(X_train,y_train)\n",
    "    pred_train_GBR = myGBR.predict(X_train)\n",
    "\n",
    "    pred_test_GBR = myGBR.predict(X_test)\n",
    "    \n",
    "    # ENet\n",
    "    ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=4.0, l1_ratio=0.005, random_state=3))\n",
    "    ENet.fit(X_train, y_train)\n",
    "    pred_train_ENet = ENet.predict(X_train)\n",
    "    pred_test_ENet = ENet.predict(X_test) \n",
    "    \n",
    "    # LGB\n",
    "    myLGB = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n",
    "                              learning_rate=0.05, n_estimators=600,\n",
    "                              max_bin = 50, bagging_fraction = 0.6,\n",
    "                              bagging_freq = 5, feature_fraction = 0.25,\n",
    "                              feature_fraction_seed=9, bagging_seed=9,\n",
    "                              min_data_in_leaf = 6, min_sum_hessian_in_leaf = 11)\n",
    "    myLGB.fit(X_train, y_train)\n",
    "    pred_train_LGB = myLGB.predict(X_train)\n",
    "    pred_test_LGB = myLGB.predict(X_test)      \n",
    "    \n",
    "    # Stacking\n",
    "    stackedset = pd.DataFrame({'A' : []})\n",
    "    stackedset = pd.concat([stackedset,pd.DataFrame(pred_test_l2)],axis=1)\n",
    "    stackedset = pd.concat([stackedset,pd.DataFrame(pred_test_l1)],axis=1)\n",
    "    stackedset = pd.concat([stackedset,pd.DataFrame(pred_test_GBR)],axis=1)\n",
    "    stackedset = pd.concat([stackedset,pd.DataFrame(pred_test_ENet)],axis=1)\n",
    "    stackedset = pd.concat([stackedset,pd.DataFrame(pred_test_LGB)],axis=1)\n",
    "    prod = (pred_test_l2*pred_test_l1*pred_test_GBR*pred_test_ENet*pred_test_LGB) ** (1.0/5.0)\n",
    "    stackedset = pd.concat([stackedset,pd.DataFrame(prod)],axis=1)\n",
    "    Xstack = np.array(stackedset)\n",
    "    Xstack = np.delete(Xstack, 0, axis=1)\n",
    "    l1_staked = Lasso(alpha = 0.0001,fit_intercept = True)\n",
    "    l1_staked.fit(Xstack, y_test)\n",
    "    pred_test_stack = l1_staked.predict(Xstack)\n",
    "    \n",
    "    models.append([l2Regr,l1Regr,myGBR,ENet,myLGB,l1_staked])\n",
    "    \n",
    "    test_errors_l2.append(np.square(pred_test_l2 - y_test).mean() ** 0.5)\n",
    "    test_errors_l1.append(np.square(pred_test_l1 - y_test).mean() ** 0.5)\n",
    "    test_errors_GBR.append(np.square(pred_test_GBR - y_test).mean() ** 0.5)\n",
    "    test_errors_ENet.append(np.square(pred_test_ENet - y_test).mean() ** 0.5)\n",
    "    test_errors_LGB.append(np.square(pred_test_LGB - y_test).mean() ** 0.5)\n",
    "    test_errors_stack.append(np.square(pred_test_stack - y_test).mean() ** 0.5)  \n",
    "    \n",
    "\n",
    "# Output of test set errors; they should be lower then \n",
    "print(np.mean(test_errors_l2))\n",
    "print(np.mean(test_errors_l1))\n",
    "print(np.mean(test_errors_GBR))\n",
    "print(np.mean(test_errors_ENet))\n",
    "print(np.mean(test_errors_LGB))\n",
    "print(np.mean(test_errors_stack))\n",
    "# \n",
    "# ----------------------- Scoring: predictions on the test set -------------------------------\n",
    "# \n",
    "# reading data\n",
    "scoredata = pd.read_csv('test.csv')\n",
    "\n",
    "scoredata['MSSubClass'] = scoredata['MSSubClass'].apply(str)\n",
    "scoredata['YrSold'] = scoredata['YrSold'].astype(str)\n",
    "scoredata['MoSold'] = scoredata['MoSold'].astype(str)\n",
    "# ------------- Filling in missing values, re-coding ordinal variables -------------\n",
    "scoredata = fill_missings(scoredata)\n",
    "\n",
    "scoredata['ExterQual'] = scoredata['ExterQual'].apply(QualToInt)\n",
    "scoredata['ExterCond'] = scoredata['ExterCond'].apply(QualToInt)\n",
    "scoredata['KitchenQual'] = scoredata['KitchenQual'].apply(QualToInt)\n",
    "scoredata['HeatingQC'] = scoredata['HeatingQC'].apply(QualToInt)\n",
    "scoredata['BsmtQual'] = scoredata['BsmtQual'].apply(QualToInt)\n",
    "scoredata['BsmtCond'] = scoredata['BsmtCond'].apply(QualToInt)\n",
    "scoredata['FireplaceQu'] = scoredata['FireplaceQu'].apply(QualToInt)\n",
    "scoredata['GarageQual'] = scoredata['GarageQual'].apply(QualToInt)\n",
    "scoredata['PoolQC'] = scoredata['PoolQC'].apply(QualToInt)\n",
    "scoredata['LandSlope'] = scoredata['LandSlope'].apply(SlopeToInt)\n",
    "scoredata['CentralAir'] = scoredata['CentralAir'].apply( lambda x: 0 if x == 'N' else 1) \n",
    "scoredata['Street'] = scoredata['Street'].apply( lambda x: 0 if x == 'Grvl' else 1) \n",
    "scoredata['GarageFinish'] = scoredata['GarageFinish'].apply(GFinishToInt)\n",
    "scoredata['BsmtExposure'] = scoredata['BsmtExposure'].apply(BsmtExposureToInt)\n",
    "\n",
    "scoredata['TotalSF'] = scoredata['TotalBsmtSF'] + scoredata['1stFlrSF'] + scoredata['2ndFlrSF']\n",
    "scoredata['TotalSF'] = scoredata['TotalSF'].fillna(0)\n",
    "\n",
    "scoredata['Functional_int'] = scoredata['Functional'].apply(FunctionalToInt)\n",
    "scoredata['HouseStyle_int'] = scoredata['HouseStyle'].apply(HouseStyleToInt)\n",
    "scoredata['HouseStyle_1st'] = 1*(scoredata['HouseStyle'] == '1Story')\n",
    "scoredata['HouseStyle_2st'] = 1*(scoredata['HouseStyle'] == '2Story')\n",
    "scoredata['HouseStyle_15st'] = 1*(scoredata['HouseStyle'] == '1.5Fin')\n",
    "scoredata['Foundation_int'] = scoredata['Foundation'].apply(FoundationToInt)\n",
    "scoredata['MasVnrType_int'] = scoredata['MasVnrType'].apply(MasVnrTypeToInt)\n",
    "scoredata['BsmtFinType1_int'] = scoredata['BsmtFinType1'].apply(BsmtFinType1ToInt)\n",
    "scoredata['BsmtFinType1_Unf'] = 1*(scoredata['BsmtFinType1'] == 'Unf')\n",
    "scoredata['PavedDrive'] = scoredata['PavedDrive'].apply( lambda x: 0 if x == 'Y' else 1)\n",
    "\n",
    "scoredata['HasWoodDeck'] = (scoredata['WoodDeckSF'] == 0) * 1\n",
    "scoredata['HasOpenPorch'] = (scoredata['OpenPorchSF'] == 0) * 1\n",
    "scoredata['HasEnclosedPorch'] = (scoredata['EnclosedPorch'] == 0) * 1\n",
    "scoredata['Has3SsnPorch'] = (scoredata['3SsnPorch'] == 0) * 1\n",
    "scoredata['HasScreenPorch'] = (scoredata['ScreenPorch'] == 0) * 1\n",
    "scoredata['Total_Home_Quality'] = scoredata['OverallQual'] + scoredata['OverallCond']\n",
    "# --------------- Changing newly appeared values for some predictors --------------- \n",
    "scoredata['MSSubClass'] = scoredata['MSSubClass'].apply(lambda x: '20' if x == '150' else x)\n",
    "scoredata['MSZoning'] = scoredata['MSZoning'].apply(lambda x: 'RL' if x == 'missing' else x)\n",
    "scoredata['Utilities'] = scoredata['Utilities'].apply(lambda x: 'AllPub' if x == 'missing' else x)\n",
    "scoredata['Exterior1st'] = scoredata['Exterior1st'].apply(lambda x: 'VinylSd' if x == 'missing' else x)\n",
    "scoredata['Exterior2nd'] = scoredata['Exterior2nd'].apply(lambda x: 'VinylSd' if x == 'missing' else x)\n",
    "scoredata['Functional'] = scoredata['Functional'].apply(lambda x: 'Typ' if x == 'missing' else x)\n",
    "scoredata['SaleType'] = scoredata['SaleType'].apply(lambda x: 'WD' if x == 'missing' else x)\n",
    "scoredata['SaleCondition'] = scoredata['SaleCondition'].apply(lambda x: 'Normal' if x == 'missing' else x)\n",
    "# --------------- Adding log-transformed predictors to raw data --------------- \n",
    "scoredata = addlogs(scoredata, loglist)\n",
    "# ----------------- Creating dataset for training: dummies, adding numeric variables, adding squared predictors ------\n",
    "def getdummies_transform(res, ls, decoder):\n",
    "    def encode(encode_df, le_df, enc_df):\n",
    "        encode_df = np.array(encode_df)\n",
    "        res1 = le_df.transform(encode_df).reshape(-1, 1)\n",
    "        return pd.DataFrame(enc_df.transform(res1).toarray())\n",
    "    \n",
    "    L = len(ls)\n",
    "    outres = pd.DataFrame({'A' : []})\n",
    "\n",
    "    for j in range(L):\n",
    "        l = ls[j]\n",
    "        le = decoder[j][0]\n",
    "        enc = decoder[j][1]\n",
    "        cat = encode(res[l], le, enc)\n",
    "        cat.columns = [l+str(x) for x in cat.columns]\n",
    "        outres.reset_index(drop=True, inplace=True)\n",
    "        outres = pd.concat([outres, cat], axis = 1)\n",
    "    \n",
    "    return outres\n",
    "\n",
    "df_scores = getdummies_transform(scoredata, catpredlist, decoder)\n",
    "df_scores = pd.concat([df_scores,scoredata[floatpredlist]],axis=1)\n",
    "df_scores = addSquared(df_scores, sqpredlist)\n",
    "# Converting data into numpy array\n",
    "X_score = np.array(df_scores)\n",
    "X_score = np.delete(X_score, 0, axis=1)\n",
    "# Scoring data\n",
    "M = X_score.shape[0]\n",
    "scores_fin = 1+np.zeros(M)\n",
    "\n",
    "for md in models:\n",
    "    l2 = md[0]\n",
    "    l1 = md[1]\n",
    "    GBR = md[2]\n",
    "    ENet = md[3]\n",
    "    LGB = md[4]\n",
    "    l1_stacked = md[5]\n",
    "    \n",
    "    l2_scores = l2.predict(X_score)\n",
    "    l1_scores = l1.predict(X_score)\n",
    "    GBR_scores = GBR.predict(X_score)\n",
    "    ENet_scores = ENet.predict(X_score)\n",
    "    LGB_scores = LGB.predict(X_score)\n",
    "    \n",
    "    stackedsets = pd.DataFrame({'A' : []})\n",
    "    stackedsets = pd.concat([stackedsets,pd.DataFrame(l2_scores)],axis=1)\n",
    "    stackedsets = pd.concat([stackedsets,pd.DataFrame(l1_scores)],axis=1)\n",
    "    stackedsets = pd.concat([stackedsets,pd.DataFrame(GBR_scores)],axis=1)\n",
    "    stackedsets = pd.concat([stackedsets,pd.DataFrame(ENet_scores)],axis=1)\n",
    "    stackedsets = pd.concat([stackedsets,pd.DataFrame(LGB_scores)],axis=1)\n",
    "    prod = (l2_scores*l1_scores*GBR_scores*ENet_scores*LGB_scores) ** (1.0/5.0)\n",
    "    stackedsets = pd.concat([stackedsets,pd.DataFrame(prod)],axis=1)    \n",
    "    Xstacks = np.array(stackedsets)\n",
    "    Xstacks = np.delete(Xstacks, 0, axis=1)\n",
    "    scores_fin = scores_fin * l1_stacked.predict(Xstacks)\n",
    "scores_fin = scores_fin ** (1/nF)\n",
    "    \n",
    "# Reading predictions obtained from running MICE and SVM in R  \n",
    "# Use R code provided below to get predictions \n",
    "# That is not my code, all the credit goes to https://www.kaggle.com/couyang/svm-benchmark-approach-0-11820-lb-top-13.\n",
    "#   library(tidyverse)\n",
    "#   library(mice)\n",
    "#   library(e1071)\n",
    "#   library(Metrics)\n",
    "#   library(randomForest)\n",
    "#   library(glmnet)\n",
    "  \n",
    "#   # Reading data\n",
    "#     train <- read.csv(\"D:/python/House_Prices_train.csv\", stringsAsFactors = F, sep=',')\n",
    "#     test <- read.csv(\"D:/python/House_Prices_test.csv\", stringsAsFactors = F, sep=',')\n",
    "    \n",
    "#   # Combining test and train data \n",
    "#     full <- bind_rows(train,test)\n",
    "#     SalePrice <- train$SalePrice\n",
    "#     N <- length(SalePrice)\n",
    "#     Id <- test$Id\n",
    "#     full[,c('Id','SalePrice')] <- NULL\n",
    "#     rm(train,test)\n",
    "    \n",
    "#   # Converting predictors to factor or integer\n",
    "#     chr <- full[,sapply(full,is.character)]\n",
    "#     int <- full[,sapply(full,is.integer)]\n",
    "#     fac <- chr %>% lapply(as.factor) %>% as.data.frame()\n",
    "#     full <- bind_cols(fac,int)\n",
    "#   # Running MICE based on random forest \n",
    "#     micemod <- full %>% mice(method='rf')\n",
    "#     full <- complete(micemod)\n",
    "#   # Saving train and test sets\n",
    "#     train <- full[1:N,]\n",
    "#     test<-full[(N+1):nrow(full),]\n",
    "#   # Adding dependent variable\n",
    "#     train <- cbind(train,SalePrice)\n",
    "\n",
    "#   # Modelling: SVM\n",
    "#     svm_model <- svm(SalePrice~., data=train, cost = 3.2)\n",
    "#     svm_pred_train <- predict(svm_model,newdata = train)\n",
    "#     sqrt(mean((log(svm_pred_train)-log(train$SalePrice))^2))\n",
    "#     svm_pred <- predict(svm_model,newdata = test)\n",
    "    \n",
    "#   # Writing final predictions to CSV file\n",
    "#     solution <- data.frame(Id=Id,SalePrice=svm_pred)\n",
    "#     write.csv(solution,\"D:/python/svm_solution_32.csv\",row.names = F)\n",
    "svm_solution = pd.read_csv('svm_solution_32.csv ')\n",
    "svm_solution_ln = np.log(svm_solution['SalePrice'])\n",
    "\n",
    "# Averaging stacked and SVM predictions\n",
    "fin_score = np.sqrt(scores_fin * svm_solution_ln)\n",
    "#fin_score = scores_fin\n",
    "\n",
    "Id = scoredata['Id']\n",
    "fin_score = pd.DataFrame({'SalePrice': np.exp(fin_score)-1})\n",
    "fin_data = pd.concat([Id,fin_score],axis=1)\n",
    "# Brutal approach to deal with predictions close to outer range \n",
    "q1 = fin_data['SalePrice'].quantile(0.0042)\n",
    "q2 = fin_data['SalePrice'].quantile(0.99)\n",
    "\n",
    "fin_data['SalePrice'] = fin_data['SalePrice'].apply(lambda x: x if x > q1 else x*0.77)\n",
    "fin_data['SalePrice'] = fin_data['SalePrice'].apply(lambda x: x if x < q2 else x*1.1)\n",
    "# Writing dataset for submission \n",
    "fin_data.to_csv('submit_mice.csv', sep=',', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

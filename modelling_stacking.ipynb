{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.feature_engineering_final import X_Transformer_scaled\n",
    "from ipynb.fs.full.feature_engineering_final import TargetNormalizedRegressor\n",
    "import pandas as pd\n",
    "from ipynb.fs.full.feature_engineering_final import DataLoader\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.metrics import make_scorer\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import RidgeCV\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy.ma as ma\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import skew\n",
    "from scipy.stats import boxcox_normmax\n",
    "from scipy.special import boxcox1p\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import ElasticNetCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(y_true, y_pred, sample_weight=None, multioutput='uniform_average'):\n",
    "    return np.sqrt(mean_squared_log_error(y_true, y_pred, sample_weight, multioutput))\n",
    "    \n",
    "#I just want to make rmse positive\n",
    "flipped_score = make_scorer(rmsle, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5),scoring=None):\n",
    "   \n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes,scoring = scoring)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(\"train.csv\",\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_loader.getX_train()\n",
    "Y_train = data_loader.getY_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_transformer = X_Transformer_scaled()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = x_transformer.fit_transform(X_train)\n",
    "kf = KFold(n_splits=10,shuffle = True,random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#cross validation and predicted vs measured cross validation\n",
    "xgb = XGBRegressor(objective='reg:squarederror',eval_metric = 'rmse',learning_rate=0.01,n_estimators=3460,\n",
    "                                     max_depth=3, min_child_weight=0,\n",
    "                                     gamma=0, subsample=0.7,\n",
    "                                     colsample_bytree=0.7,\n",
    "                                     nthread=-1,\n",
    "                                     scale_pos_weight=1, seed=27,\n",
    "                                     reg_alpha=0.00006)\n",
    "svr = SVR(kernel=\"rbf\",gamma=0.0003,C = 30,epsilon = 0.00008)\n",
    "\n",
    "ridge = RidgeCV(alphas=[14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5])\n",
    "\n",
    "lasso = LassoCV(cv=10)\n",
    "\n",
    "elastic_net = ElasticNetCV(max_iter=1e7, alphas=[0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007],\n",
    "                                        cv=kf, l1_ratio=[0.8, 0.85, 0.9, 0.95, 0.99, 1])\n",
    "\n",
    "gbr = GradientBoostingRegressor(n_estimators=3700, learning_rate=0.01,\n",
    "                                   max_depth=3, max_features='sqrt',\n",
    "                                   loss='huber', random_state =42,subsample = 0.7)\n",
    "\n",
    "\n",
    "scvr = TargetNormalizedRegressor(StackingCVRegressor(regressors=(xgb,svr,ridge,lasso,elastic_net,gbr),\n",
    "                                meta_regressor=elastic_net,cv=10,\n",
    "                                use_features_in_secondary=True,\n",
    "                                  n_jobs = -1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "scores = cross_val_score(scvr, X_train, Y_train, cv=kf,n_jobs=-1,scoring = flipped_score)\n",
    "print(\"Rmse log average: %0.5f (+/- %0.5f)\" % (scores.mean(), scores.std() * 2))\n",
    "print(\"Rmse log median: %0.5f\" % (np.median(scores)))\n",
    "predicted = cross_val_predict(scvr, X_train, Y_train, cv=kf,n_jobs=-1)\n",
    "print(scores)\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(Y_train, predicted, edgecolors=(0, 0, 0))\n",
    "ax.plot([Y_train.min(), Y_train.max()], [Y_train.min(), Y_train.max()], 'k--', lw=4)\n",
    "ax.set_xlabel('Measured')\n",
    "ax.set_ylabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning curve of best model\n",
    "plot_learning_curve(scvr, \"Title\", X_train, Y_train, None, cv=kf, n_jobs=-1,scoring = flipped_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
